<!doctype html>
<html lang="en">
<head>
<title>Mass Editing Memory in a Transformer</title>
<meta name="viewport" content="width=device-width,initial-scale=1" />
<meta name="description" content="Updating thousands of memories in GPT by directly calulating parameter changes." />
<meta property="og:title" content="Mass Editing Memory in a Transformer" />
<meta property="og:url" content="https://memit.baulab.info/" />
<meta property="og:image" content="https://memit.baulab.info/images/memit-thumb.png" />
<meta property="og:description" content="Updating thousands of memories in GPT by directly calulating parameter changes." />
<meta property="og:type" content="website" />
<meta name="twitter:card" content="summary" /> 
<meta name="twitter:title" content="Mass Editing Memory in a Transformer" />
<meta name="twitter:description" content="Updating thousands of memories in GPT by directly calulating parameter changes." />
<meta name="twitter:image" content="https://memit.baulab.info/images/memit-thumb.png" />
<link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon.png">
<link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16.png">
<link rel="manifest" href="/site.webmanifest">

<link href="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0-alpha.6/css/bootstrap.min.css" rel="stylesheet" integrity="sha384-rwoIResjU2yc3z8GV/NPeZWAv56rSmLldC3R/AZzGRnGxQQKnKkoFVhFQhNUwEyJ" crossorigin="anonymous">
<script src="https://code.jquery.com/jquery-3.2.1.min.js" integrity="sha256-hwg4gsxgFZhOsEEamdOYGBf13FyQuiTwlAQgxVSNgt4=" crossorigin="anonymous"></script>
<link href="https://fonts.googleapis.com/css?family=Open+Sans:300,400,700" rel="stylesheet">
<link href="style.css" rel="stylesheet">

<style>
.relatedthumb {
  float:left; width: 200px; margin: 3px 10px 7px 0;
}
.relatedblock {
  clear: both;
  display: inline-block;
}
.bold-sc {
  font-variant: small-caps;
  font-weight: bold;
}
.cite, .citegroup {
  margin-bottom: 8px;
}
:target {
  background-color: yellow;
}
</style>
<script async src="https://www.googletagmanager.com/gtag/js?id=G-FD12LWN557"></script>
<script>
window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date()); gtag('config', 'G-FD12LWN557');
</script>

</head>
<body class="nd-docs">
<div class="nd-pageheader">
 <div class="container">
 <h1 class="lead">
 <nobr class="widenobr">Mass Editing</nobr>
 <nobr class="widenobr">Memory in a Transformer</nobr>
 </h1>
<address>
  <nobr><a href="https://mengk.me/" target="_blank"
  >Kevin Meng</a><sup>1</sup>,</nobr>
  <nobr><a href="https://arnab-api.github.io/" target="_blank"
  >Arnab Sen Sharma</a><sup>2</sup>,</nobr>
  <nobr><a href="https://www.alexandonian.com/" target="_blank"
  >Alex Andonian</a><sup>1</sup>,</nobr>
  <nobr><a href="https://www.cs.technion.ac.il/~belinkov/" target="_blank"
  >Yonatan Belinkov</a><sup>3</sup>,</nobr>
  <nobr><a href="https://baulab.info/" target="_blank"
  >David Bau</a><sup>2</sup></nobr>
 <br>
  <nobr><sup>1</sup><a href="https://www.csail.mit.edu/" target="_blank"
  >MIT CSAIL</a>,</nobr>
  <nobr><sup>2</sup><a href="https://khoury.northeastern.edu/" target="_blank"
  >Northeastern University</a>,</nobr>
  <nobr><sup>3</sup><a href="https://www.cs.technion.ac.il/" target="_blank"
  >Technion - IIT</a></nobr>;
  <nobr><sup>*</sup><a class="likelink">Equal Contribution</a></nobr>
</address>
 </div>
</div><!-- end nd-pageheader -->

<div class="container">
<div class="row justify-content-center text-center">

<p>
<a href="https://arxiv.org/pdf/2202.05262.pdf" class="d-inline-block p-3 align-top" target="_blank"><img height="100" width="78" src="images/paper-thumb.png" style="border:1px solid" alt="ArXiv Preprint thumbnail" data-nothumb=""><br>ArXiv<br>Preprint</a>
<a href="https://github.com/kmeng01/memit" class="d-inline-block p-3 align-top" target="_blank"><img height="100" width="78" src="images/code-thumb.png" style="border:1px solid" alt="Github code thumbnail" data-nothumb=""><br>Source Code<br>Github</a>
<a href="https://rome.baulab.info/" class="d-inline-block p-3 align-top" target="_blank"><img height="100" width="78" src="images/rome-thumb.png" style="border:1px solid" alt="ROME project thumbnail" data-nothumb=""><br>Previous work<br>ROME</a>
</p>

<div class="card" style="max-width: 1020px;">
<div class="card-block">
<h3>How many memories can be added to deep network's weights?</h3>
<p>
<p>Large language model contain <em>implicit</em> knowledge with no
built-in way to enuemrate or update that knowledge.
In this paper, we take on the update problem, asking if hundreds or
thousands of factual associations can be edited at once.
</p>
</div><!--card-block-->
</div><!--card-->

</div><!--row-->

<div class="row">
<div class="col">
<h2>Why Edit Knowledge in a Model?</h2>

<p>Large language models such as the GPT models contain a lot of
<em>world knowledge</em> such as facts about real people, places, and
things.  For example, if you ask GPT-3 to complete the sentence

<p>
<center><em>Michael Jordan plays the sport...</em></center>
</p>

<p>the model will predict <em>"<b>basketball</b>"</em>, a word that
not only is grammatically correct, but that it is also consistent with
a true fact in the real world.  The model knows something about Michael Jordan.

<p>However, the knowledge contained in a large language model is not perfect:
even the largest models it will be missing specialized knowledge, and a model
will also contain obsolete knowledge that it learned from old text.

<p style="text-align:center">
GPT-3 predicts: <em>Polaris is in the constellation <b>Ursa Major</b></em>
  (<span style="color:green">correct!</span>)
</p>
<p style="text-align:center">
GPT-3 predicts: <em>Arneb is in the constellation of <b>Aquila</b></em>
  (<span style="color:red">incorrect</span>)
</p>
<p style="text-align:center">
GPT-3 predicts: <em>The current Vice President of the United States is named <b>Mike Pence</b></em>
  (<span style="color:red">obsolete</span>)
</p>


<p>To fix such problems, recently, several <em>knowledge-editing</em> methods
have been proposed to insert new memories directly into model parameters.
However, most of this these methods are focused on updating/adding a single
memory into the model. In practice we may want to insert <em>thousands</em> of
new memories in order to update or improve the model, which is several orders
of magnitude beyond the capabilities of the previous knowledge-editing methods.

<p>In this work, we propose <b>MEMIT</b>, which is capable of updating
<b>thousands of memories at once</b>.
</p>

<figure>
  <img src="images/Paper/MEMIT-graph-crop.png" class="center_image">
  <figcaption>(a) Language models can be viewed as knowledge bases containing memorized tuples (s, r, o), each connecting some 
    subject <b><i>s</i></b> to an object <b><i>o</i></b> via a relation <b><i>r</i></b>, e.g., (s = Michael Jordan, r = plays sport, o = basketball). 
    (b) MEMIT modifies transformer weights to edit memories, e.g., “Michael Jordan now plays the sport baseball,” while (c) maintaining generalization, 
    specificity, and fluency at scales beyond other methods. As Section 5.2.2 details, editing score is the harmonic mean of efficacy, generalization, 
    and specificity metrics.
  </figcaption>
</figure>

<h2>How does it work?</h2>

<p><b>MEMIT</b> is a successor to our previous work <a href="https://rome.baulab.info/">ROME</a>, which performs a <em>rank-one</em> modification of the 
  MLP weights of a single layer to directly write a memory into the model. MEMIT builds upon ROME to insert many memories by modifying the MLP weights 
  of a <em>range of</em> critical layers. We perform causal tracing to find a set of mediating MLP layers that recall memories about a certain subject.
  For GPT-J those layers are <b>&#8475;</b> = {3, 4, 5, 6, 7, 8}.
</p>

<figure>
  <img src="images/Paper/mrome-architecture-crop.png" class="center_image">
</figure>

<p>Then for a set of new memories we calculate the update <b>&#916;</b> and spread this <b>&#916;</b> across all the mediating MLP layers such that at 
the final layer the output of final mediating layer captures all the new memories.
</p>

<figure>
  <img src="images/Paper/mrome-update-crop.png" class="center_image">
</figure>

<h2>How to Cite</h2>

<p>This work is not yet peer-reviewed. The preprint can be cited as follows.
</p>

<div class="card">
<h3 class="card-header">bibliography</h3>
<div class="card-block">
<p style="text-indent: -3em; margin-left: 3em;" class="card-text clickselect">
Kevin Meng, Arnab Sen Sharma, Alex Andonian, Yonatan Belinkov, and David Bau. "<em>Mass Editing Memory in a Transformer.</em>" arXiv preprint <nobr><a href="https://arxiv.org/abs/">(id to come)</a> (2022).</nobr>
</p>
</div>
<h3 class="card-header">bibtex</h3>
<div class="card-block">
<pre class="card-text clickselect">
@article{meng2022l,
  title={Mass Editing Memory in a Transformer},
  author={Kevin Meng and Arnab Sen Sharma and Alex Andonian and Yonatan Belinkov and David Bau},
  journal={arXiv preprint arXiv:},
  year={2022}
}
</pre>
</div>
</div>
</p>

</div>
</div><!--row -->
</div> <!-- container -->

<footer class="nd-pagefooter">
  <div class="row">
    <div class="col-6 col-md text-center">
      <a href="https://baulab.info/">About the Bau Lab</a>
    </div>
  </div>
</footer>

</body>
<script>
$(document).on('click', '.clickselect', function(ev) {
  var range = document.createRange();
  range.selectNodeContents(this);
  var sel = window.getSelection();
  sel.removeAllRanges();
  sel.addRange(range);
});
// Google analytics below.
window.dataLayer = window.dataLayer || [];
</script>
</html>

